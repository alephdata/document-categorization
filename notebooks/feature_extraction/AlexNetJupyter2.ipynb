{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/dssg/occrp/data/input/tobacco_dataset/\n",
      "['ADVE', 'Email', 'Form', 'Letter', 'Memo', 'News', 'Note', 'Report', 'Resume', 'Scientific']\n",
      "Types of documents found: 44\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import os, sys, path\n",
    "\n",
    "# getting the dir of this file and add parent dir to sys path\n",
    "current = os.path.abspath(\"\")\n",
    "parent = os.path.dirname(current)\n",
    "grandparent = os.path.dirname(parent)\n",
    "sys.path.append(parent)\n",
    "sys.path.append(grandparent)\n",
    "import src.config as config\n",
    "\n",
    "\n",
    "## For computers with no GPU. Remove if GPU is present.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "## Folder names inside our data directory\n",
    "DATA_PATH_ABS: str = config.settings.DATA_PATH_ABS_TOBACCO_DATASET\n",
    "print(DATA_PATH_ABS)\n",
    "\n",
    "## Different document classes in our data directory.\n",
    "doc_types = os.listdir(DATA_PATH_ABS)\n",
    "print(doc_types)\n",
    "\n",
    "print(\"Types of documents found:\", len(DATA_PATH_ABS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "# Get all file types\n",
    "for item in doc_types:\n",
    "    all_docs = os.listdir(DATA_PATH_ABS + item)\n",
    "\n",
    "    # Add them to the list:\n",
    "    for doc in all_docs:\n",
    "        docs.append((item, str(DATA_PATH_ABS + item) + \"/\" + doc))\n",
    "\n",
    "# print(docs)\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  doc type                                              image\n",
      "0     ADVE  /data/dssg/occrp/data/input/tobacco_dataset/AD...\n",
      "1     ADVE  /data/dssg/occrp/data/input/tobacco_dataset/AD...\n",
      "2     ADVE  /data/dssg/occrp/data/input/tobacco_dataset/AD...\n",
      "3     ADVE  /data/dssg/occrp/data/input/tobacco_dataset/AD...\n",
      "4     ADVE  /data/dssg/occrp/data/input/tobacco_dataset/AD...\n",
      "Total number of scanned pages in the dataset: 3492\n",
      "Index(['doc type', 'image'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Build a dataframe:\n",
    "docs_df = pd.DataFrame(data=docs, columns=[\"doc type\", \"image\"])\n",
    "print(docs_df.head())\n",
    "print(\"Total number of scanned pages in the dataset:\", len(docs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rooms in each category:\n",
      "Memo          621\n",
      "Email         600\n",
      "Letter        568\n",
      "Form          432\n",
      "Report        266\n",
      "Scientific    262\n",
      "ADVE          231\n",
      "Note          202\n",
      "News          189\n",
      "Resume        121\n",
      "Name: doc type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## We count how many images correspond to each\n",
    "## document type.\n",
    "doc_count = docs_df[\"doc type\"].value_counts()\n",
    "\n",
    "## We print the results.\n",
    "print(\"Rooms in each category:\")\n",
    "print(doc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of  10  faulty files.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "im_size = 227\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "type_counter = 0\n",
    "file_counter = 0\n",
    "faulty = []\n",
    "\n",
    "\n",
    "## In this loop, we extract all document images,\n",
    "## and resize them to 227x227x3 (color image)\n",
    "for i in doc_types:\n",
    "    data_path = DATA_PATH_ABS + str(i)\n",
    "    filenames = [i for i in os.listdir(data_path)]\n",
    "    for f in filenames:\n",
    "        img = cv2.imread(data_path + \"/\" + f)  # reading image as array\n",
    "        v_type = type(img)\n",
    "        if v_type is np.ndarray:\n",
    "            # print(f,\" : \", img.shape[0], \" x \", img.shape[1])\n",
    "            img = cv2.resize(img, (im_size, im_size))\n",
    "            images.append(img)\n",
    "            labels.append(i)\n",
    "\n",
    "        ## Save the positions of damaged files:\n",
    "        if v_type is not np.ndarray:\n",
    "            type_counter = type_counter + 1\n",
    "            faulty.append(file_counter)\n",
    "            # print( \"Faulty file!\")\n",
    "        file_counter = file_counter + 1\n",
    "\n",
    "\n",
    "print(\"There are a total of \", type_counter, \" faulty files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of image tensor is: (3482, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "## We convert images into a darray:\n",
    "images = np.array(images)\n",
    "print(\"Size of image tensor is:\", images.shape)\n",
    "\n",
    "## We resize darray entries to be between 0 and 1.\n",
    "images = images.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original size of our database is: (3492, 2)\n",
      "We want to eliminate the rows:  [225, 830, 1262, 1781, 2428, 2640, 2842, 3070, 3229, 3491]\n",
      "The new dimensions are: (3482, 2)\n"
     ]
    }
   ],
   "source": [
    "## Eliminate damaged files from database.\n",
    "print(\"The original size of our database is:\", docs_df.shape)\n",
    "print(\"We want to eliminate the rows: \", faulty)\n",
    "docs_df = docs_df.drop(labels=faulty, axis=0)\n",
    "# docs_df2 = docs_df.reindex(axis=0)\n",
    "print(\"The new dimensions are:\", docs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3482, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "## To train the CNN, we need to encode our response as\n",
    "## a 10-long vector with 0's and 1's. For this, we use\n",
    "## labelencoder + onehotencoder.\n",
    "y = docs_df[\"doc type\"].values\n",
    "# print(y[:5])\n",
    "\n",
    "y_labelencoder = LabelEncoder()\n",
    "y = y_labelencoder.fit_transform(y)\n",
    "# print(y[:5])\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "# print(y[:5])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categories=\"auto\", sparse=False)\n",
    "Y = onehotencoder.fit_transform(y)\n",
    "print(Y.shape)\n",
    "\n",
    "# OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3133, 227, 227, 3)\n",
      "(3133, 10)\n",
      "(349, 227, 227, 3)\n",
      "(349, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## We shuffle the images:\n",
    "images, Y = shuffle(images, Y, random_state=5)\n",
    "\n",
    "## Generate training/testing datasets.\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.1, random_state=1)\n",
    "\n",
    "# Display dimensions of training/testing sets:\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 17:29:43.076634: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/holtel/.local/share/virtualenvs/dssgxdfki2022-occrp-Q6x3GZWS/lib64/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-06-27 17:29:43.076697: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "## Note: Original code uses tensorflow v1,\n",
    "##      but local installation is v2. To\n",
    "##      correct this, we load tensorflow.compat,\n",
    "##      which is a module of TF that contains v1.\n",
    "##      to use v1, we use tensorflow.compat.v1\n",
    "from tensorflow import compat as tf\n",
    "\n",
    "# placeholders are not executable immediately so we need to disable eager exicution in TF 2 not in 1\n",
    "tf.v1.disable_eager_execution()\n",
    "\n",
    "num_classes = 10\n",
    "x = tf.v1.placeholder(tf.v1.float32, shape=[None, 227, 227, 3])\n",
    "y_ = tf.v1.placeholder(tf.v1.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We create a dictionary with the weights/biases needed for AlexNet CNN.\n",
    "weights = {\n",
    "    \"w1\": tf.v1.Variable(tf.v1.random_normal(shape=[11, 11, 3, 96], dtype=tf.v1.float32), name=\"w1\"),\n",
    "    \"w2\": tf.v1.Variable(tf.v1.random_normal(shape=[5, 5, 96, 256], dtype=tf.v1.float32), name=\"w2\"),\n",
    "    \"w3\": tf.v1.Variable(tf.v1.random_normal(shape=[3, 3, 256, 384], dtype=tf.v1.float32), name=\"w3\"),\n",
    "    \"w4\": tf.v1.Variable(tf.v1.random_normal(shape=[3, 3, 384, 384], dtype=tf.v1.float32), name=\"w4\"),\n",
    "    \"w5\": tf.v1.Variable(tf.v1.random_normal(shape=[3, 3, 384, 256], dtype=tf.v1.float32), name=\"w5\"),\n",
    "    \"wfc1\": tf.v1.Variable(tf.v1.random_normal(shape=[6 * 6 * 256, 4096], dtype=tf.v1.float32), name=\"wfc1\"),\n",
    "    \"wfc2\": tf.v1.Variable(tf.v1.random_normal(shape=[4096, 4096], dtype=tf.v1.float32), name=\"wfc2\"),\n",
    "    \"wout\": tf.v1.Variable(tf.v1.random_normal(shape=[4096, num_classes], dtype=tf.v1.float32), name=\"wout\"),\n",
    "}\n",
    "biases = {\n",
    "    \"b1\": tf.v1.Variable(tf.v1.random_normal(shape=[96]), name=\"b1\"),\n",
    "    \"b2\": tf.v1.Variable(tf.v1.random_normal(shape=[256]), name=\"b2\"),\n",
    "    \"b3\": tf.v1.Variable(tf.v1.random_normal(shape=[384]), name=\"b3\"),\n",
    "    \"b4\": tf.v1.Variable(tf.v1.random_normal(shape=[384]), name=\"b4\"),\n",
    "    \"b5\": tf.v1.Variable(tf.v1.random_normal(shape=[256]), name=\"b5\"),\n",
    "    \"bfc1\": tf.v1.Variable(tf.v1.random_normal(shape=[4096]), name=\"bfc1\"),\n",
    "    \"bfc2\": tf.v1.Variable(tf.v1.random_normal(shape=[4096]), name=\"bfc2\"),\n",
    "    \"bout\": tf.v1.Variable(tf.v1.random_normal(shape=[num_classes]), name=\"bout\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We define the AlexNet CNN:\n",
    "def alex_net(x, weights, biases):\n",
    "    x = tf.v1.reshape(x, shape=[-1, 227, 227, 3])\n",
    "    print(\"*******************************************\")\n",
    "    print(\"The size of x is: \", x.shape)\n",
    "\n",
    "    ## 1st convolutional + maxpool layers\n",
    "    conv1_in = tf.v1.nn.conv2d(x, weights[\"w1\"], strides=[1, 4, 4, 1], padding=\"SAME\")\n",
    "    conv1_in = tf.v1.nn.bias_add(conv1_in, biases[\"b1\"])\n",
    "    conv1 = tf.v1.nn.relu(conv1_in)\n",
    "\n",
    "    maxpool1 = tf.v1.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    print(\"Size after 1st convolutional layer: \", maxpool1.shape)\n",
    "\n",
    "    ## 2nd convolutional + maxpool layers\n",
    "    conv2_in = tf.v1.nn.conv2d(maxpool1, weights[\"w2\"], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv2_in = tf.v1.nn.bias_add(conv2_in, biases[\"b2\"])\n",
    "    conv2 = tf.v1.nn.relu(conv2_in)\n",
    "\n",
    "    maxpool2 = tf.v1.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    print(\"Size after 2nd convolutional layer: \", maxpool2.shape)\n",
    "\n",
    "    ## 3rd convolutional layer\n",
    "    conv3_in = tf.v1.nn.conv2d(maxpool2, weights[\"w3\"], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv3_in = tf.v1.nn.bias_add(conv3_in, biases[\"b3\"])\n",
    "    conv3 = tf.v1.nn.relu(conv3_in)\n",
    "    print(\"Size after 3rd convolutional layer: \", conv3.shape)\n",
    "\n",
    "    ## 4th convolutional layer\n",
    "    conv4_in = tf.v1.nn.conv2d(conv3, weights[\"w4\"], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv4_in = tf.v1.nn.bias_add(conv4_in, biases[\"b4\"])\n",
    "    conv4 = tf.v1.nn.relu(conv4_in)\n",
    "    print(\"Size after 4th convolutional layer: \", conv4.shape)\n",
    "\n",
    "    ## 5th convolutional + maxpool layer:\n",
    "    conv5_in = tf.v1.nn.conv2d(conv4, weights[\"w5\"], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    conv5_in = tf.v1.nn.bias_add(conv5_in, biases[\"b5\"])\n",
    "    conv5 = tf.v1.nn.relu(conv5_in)\n",
    "\n",
    "    maxpool5 = tf.v1.nn.max_pool(conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    print(\"Size after 5th convolutional layer: \", maxpool5.shape)\n",
    "\n",
    "    ## 6th flat layer.\n",
    "    fc6 = tf.v1.reshape(maxpool5, [-1, weights[\"wfc1\"].get_shape().as_list()[0]])\n",
    "    fc6 = tf.v1.add(tf.v1.matmul(fc6, weights[\"wfc1\"]), biases[\"bfc1\"])\n",
    "    fc6 = tf.v1.nn.relu(fc6)\n",
    "    print(\"Size after reshaping the image is: \", fc6.shape)\n",
    "\n",
    "    ## 7th flat layer:\n",
    "    fc7 = tf.v1.nn.relu_layer(fc6, weights[\"wfc2\"], biases[\"bfc2\"])\n",
    "    print(\"Size after reshaping the image is: \", fc7.shape)\n",
    "\n",
    "    ## 8th output layer:\n",
    "    fc8 = tf.v1.add(tf.v1.matmul(fc7, weights[\"wout\"]), biases[\"bout\"])\n",
    "    out = tf.v1.nn.softmax(fc8)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************\n",
      "The size of x is:  (None, 227, 227, 3)\n",
      "Size after 1st convolutional layer:  (None, 28, 28, 96)\n",
      "Size after 2nd convolutional layer:  (None, 13, 13, 256)\n",
      "Size after 3rd convolutional layer:  (None, 13, 13, 384)\n",
      "Size after 4th convolutional layer:  (None, 13, 13, 384)\n",
      "Size after 5th convolutional layer:  (None, 6, 6, 256)\n",
      "Size after reshaping the image is:  (None, 4096)\n",
      "Size after reshaping the image is:  (None, 4096)\n",
      "Tensor(\"Softmax:0\", shape=(None, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Create the model:\n",
    "model = alex_net(x, weights, biases)\n",
    "print(model)\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish learning rate, cost and optimizer algorithm.\n",
    "learning_rate = 0.05\n",
    "cost = tf.v1.reduce_mean(tf.v1.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=y_))\n",
    "optimizer = tf.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "## Initialize all the weights and biases of the model.\n",
    "init = tf.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3133, 227, 227, 3)\n",
      "(3133, 10)\n",
      "(349, 227, 227, 3)\n",
      "(349, 10)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Display dimensions of training/testing sets:\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "## Define number of epochs and start session\n",
    "cost_history = []\n",
    "n_epochs = 100\n",
    "sess = tf.v1.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "## We run for 100 epochs:\n",
    "for i in range(n_epochs):\n",
    "    print(\"Starting Epoch \", i)\n",
    "\n",
    "    ## Select a batch of size 20\n",
    "    batchIndex = random.sample(range(3133), 20)\n",
    "    train_x_ = train_x[batchIndex, :]\n",
    "    train_y_ = train_y[batchIndex, :]\n",
    "\n",
    "    ## Update weights/biases with this batch.\n",
    "    a, c = sess.run([optimizer, cost], feed_dict={x: train_x_, y_: train_y_})\n",
    "    cost_history = np.append(cost_history, c)\n",
    "    print(\"Epoch \", i, \" - \", \"Cost: \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n",
      "(4, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "## Some small experiments (unrelated/unnecessary)\n",
    "\n",
    "import random\n",
    "\n",
    "## Experiment with subsetting datasets:\n",
    "batchIndex = random.sample(range(3133), 4)\n",
    "train_y_ = train_y[batchIndex, :]\n",
    "print(train_y_.shape)\n",
    "\n",
    "train_x_ = train_x[batchIndex]\n",
    "print(train_x_.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dssgxdfki2022-occrp-Q6x3GZWS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47946eec2191886fcaa9dd92f6aeed38a1126d6d74f01b2379753189db98146d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
