{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# https://theailearner.com/2019/07/06/data-augmentation-with-keras-imagedatagenerator/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tensorflow model.\n",
    "def create_model_AlexNet(\n",
    "    verbose: bool = False, dropout_param: float = 0.0, regularization_param: float = 0.0, cnn_layer_filters_value: int = 256\n",
    ") -> Sequential:\n",
    "    \"\"\"Receives:\n",
    "        -\n",
    "    Returns:\n",
    "        Compiled AlexNet model with input layer of 227x227x3 and output layer with 16 nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the model\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            keras.layers.Conv2D(\n",
    "                filters=96,\n",
    "                kernel_size=(11, 11),\n",
    "                strides=(4, 4),\n",
    "                activation=\"relu\",\n",
    "                input_shape=(227, 227, 3),\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=regularization_param),\n",
    "            ),  # NOQA E501\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "            tf.keras.layers.SpatialDropout2D(rate=dropout_param),\n",
    "            keras.layers.Conv2D(\n",
    "                filters=256,\n",
    "                kernel_size=(5, 5),\n",
    "                strides=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=regularization_param),\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "            tf.keras.layers.SpatialDropout2D(rate=dropout_param),\n",
    "            keras.layers.Conv2D(\n",
    "                filters=384,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=regularization_param),\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(\n",
    "                filters=384,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=regularization_param),\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Conv2D(\n",
    "                filters=cnn_layer_filters_value,\n",
    "                kernel_size=(3, 3),\n",
    "                strides=(1, 1),\n",
    "                activation=\"relu\",\n",
    "                padding=\"same\",\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l=regularization_param),\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(4096, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(4096, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = create_model_AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image generators\n",
    "\n",
    "# Training ImagaDataGenerator with Augmentation transf.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    rotation_range=15,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    "    channel_shift_range=0.9,\n",
    "    height_shift_range=0.05,\n",
    "    width_shift_range=0.1,\n",
    "    brightness_range=[0.2, 1.0],\n",
    ")\n",
    "# Validation ImageDataGenerator with rescaling.\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255, validation_split=0.2, samplewise_center=True, samplewise_std_normalization=True\n",
    ")\n",
    "# Testing ImageDataGenerator with rescaling.\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255, samplewise_center=True, samplewise_std_normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set classes\n",
    "classes = [\n",
    "    \"bank-statements\",\n",
    "    \"contracts\",\n",
    "    \"company-registry\",\n",
    "    \"court-documents\",\n",
    "    \"gazettes\",\n",
    "    \"invoices\",\n",
    "    \"middle-page\",\n",
    "    \"passport-scan\",\n",
    "    \"receipts\",\n",
    "    \"shipping-receipts\",\n",
    "    \"transcripts\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10737 images belonging to 11 classes.\n",
      "Found 2679 images belonging to 11 classes.\n",
      "Found 687 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create a flow from the directory for validation data - seed=42\n",
    "# Create a flow from the directory using same seed and 'training' subset.\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    \"/data/dssg/occrp/data/processed_clean\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    target_size=(227, 227),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    "    color_mode=\"rgb\",\n",
    "    classes=classes,\n",
    ")\n",
    "# Choose subset = 'validation'\n",
    "valid_gen = valid_datagen.flow_from_directory(\n",
    "    \"/data/dssg/occrp/data/processed_clean\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    target_size=(227, 227),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    "    color_mode=\"rgb\",\n",
    "    classes=classes,\n",
    ")\n",
    "\n",
    "# Create flow from test directory\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"/data/dssg/occrp/data/testing_data/web\",\n",
    "    target_size=(227, 227),\n",
    "    batch_size=32,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"sparse\",\n",
    "    seed=42,\n",
    "    classes=classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-PA4e7Co-/lib64/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-PA4e7Co-/lib64/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-PA4e7Co-/lib64/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create flow from dataframe\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/data/dssg/occrp/data/input/rvl-cdip/labels/train.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m train_gen_d \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39;49mflow_from_dataframe(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     train_df, directory \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/data/dssg/occrp/data/input/rvl-cdip/images/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     subset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m,\\\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     x_col\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m, y_col\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\\\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, seed\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m, target_size\u001b[39m=\u001b[39;49m(\u001b[39m227\u001b[39;49m, \u001b[39m227\u001b[39;49m),\\\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, class_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msparse\u001b[39;49m\u001b[39m'\u001b[39;49m,color_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrgb\u001b[39;49m\u001b[39m'\u001b[39;49m, classes \u001b[39m=\u001b[39;49m classes)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Choose subset = 'validation'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/jsanchez/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m val_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/data/dssg/occrp/data/input/rvl-cdip/labels/val.txt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-PA4e7Co-/lib/python3.8/site-packages/keras/preprocessing/image.py:1610\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdrop_duplicates\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m   1605\u001b[0m   warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1606\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1607\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1608\u001b[0m       \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m-> 1610\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameIterator(\n\u001b[1;32m   1611\u001b[0m     dataframe,\n\u001b[1;32m   1612\u001b[0m     directory,\n\u001b[1;32m   1613\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1614\u001b[0m     x_col\u001b[39m=\u001b[39;49mx_col,\n\u001b[1;32m   1615\u001b[0m     y_col\u001b[39m=\u001b[39;49my_col,\n\u001b[1;32m   1616\u001b[0m     weight_col\u001b[39m=\u001b[39;49mweight_col,\n\u001b[1;32m   1617\u001b[0m     target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[1;32m   1618\u001b[0m     color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[1;32m   1619\u001b[0m     classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[1;32m   1620\u001b[0m     class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[1;32m   1621\u001b[0m     data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[1;32m   1622\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1623\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1624\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   1625\u001b[0m     save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[1;32m   1626\u001b[0m     save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[1;32m   1627\u001b[0m     save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[1;32m   1628\u001b[0m     subset\u001b[39m=\u001b[39;49msubset,\n\u001b[1;32m   1629\u001b[0m     interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[1;32m   1630\u001b[0m     validate_filenames\u001b[39m=\u001b[39;49mvalidate_filenames,\n\u001b[1;32m   1631\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-PA4e7Co-/lib/python3.8/site-packages/keras/preprocessing/image.py:853\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m dtype\n\u001b[1;32m    852\u001b[0m \u001b[39m# check that inputs match the required class_mode\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params(df, x_col, y_col, weight_col, classes)\n\u001b[1;32m    854\u001b[0m \u001b[39mif\u001b[39;00m validate_filenames:  \u001b[39m# check which image files are valid and keep them\u001b[39;00m\n\u001b[1;32m    855\u001b[0m   df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filter_valid_filepaths(df, x_col)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-PA4e7Co-/lib/python3.8/site-packages/keras/preprocessing/image.py:901\u001b[0m, in \u001b[0;36mDataFrameIterator._check_params\u001b[0;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[1;32m    896\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    897\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mIf class_mode=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, y_col must be a list. Received \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    898\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_mode,\n\u001b[1;32m    899\u001b[0m           \u001b[39mtype\u001b[39m(y_col)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[1;32m    900\u001b[0m \u001b[39m# check that filenames/filepaths column values are all strings\u001b[39;00m\n\u001b[0;32m--> 901\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(df[x_col]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m))):\n\u001b[1;32m    902\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    903\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mAll values in column x_col=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m must be strings.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(x_col))\n\u001b[1;32m    904\u001b[0m \u001b[39m# check labels are string if class_mode is binary or sparse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-PA4e7Co-/lib64/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-PA4e7Co-/lib64/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "# Create flow from dataframe\n",
    "train_gen_d = train_datagen.flow_from_dataframe(\n",
    "    \"/data/dssg/occrp/data/input/rvl-cdip/labels/train.txt\",\n",
    "    subset=\"training\",\n",
    "    x_col=\"\",\n",
    "    y_col=\"\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    target_size=(227, 227),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    "    color_mode=\"rgb\",\n",
    "    classes=classes,\n",
    ")\n",
    "# Choose subset = 'validation'\n",
    "valid_gen_d = valid_datagen.flow_from_dataframe(\n",
    "    \"/data/dssg/occrp/data/input/rvl-cdip/labels/val.txt\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    target_size=(227, 227),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    "    color_mode=\"rgb\",\n",
    "    classes=classes,\n",
    ")\n",
    "\n",
    "# Create flow from test directory\n",
    "test_generator_d = test_datagen.flow_from_dataframe(\n",
    "    \"/data/dssg/occrp/data/input/rvl-cdip/labels/test.txt\",\n",
    "    target_size=(227, 227),\n",
    "    batch_size=32,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"sparse\",\n",
    "    seed=42,\n",
    "    classes=classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagesq/q/o/c/qoc54c00/80035521.tif</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagese/e/w/c/ewc23d00/513280028.tif</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imagesw/w/b/t/wbt26e00/2053453161.tif</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imagesm/m/k/m/mkm05e00/2040792992_2040792994.tif</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imageso/o/e/x/oex80d00/522787731+-7732.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319995</th>\n",
       "      <td>imagesu/u/p/p/upp04f00/0000282789.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319996</th>\n",
       "      <td>imagesa/a/c/z/acz60f00/0011972032.tif</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319997</th>\n",
       "      <td>imagesu/u/j/m/ujm20a00/10155388.tif</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319998</th>\n",
       "      <td>imagesd/d/r/r/drr93f00/0000343578.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319999</th>\n",
       "      <td>imagesp/p/j/x/pjx11d00/518223252+-3253.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename class Unnamed: 2\n",
       "0                    imagesq/q/o/c/qoc54c00/80035521.tif    15        NaN\n",
       "1                   imagese/e/w/c/ewc23d00/513280028.tif     1        NaN\n",
       "2                  imagesw/w/b/t/wbt26e00/2053453161.tif     7        NaN\n",
       "3       imagesm/m/k/m/mkm05e00/2040792992_2040792994.tif    10        NaN\n",
       "4             imageso/o/e/x/oex80d00/522787731+-7732.tif     3        NaN\n",
       "...                                                  ...   ...        ...\n",
       "319995             imagesu/u/p/p/upp04f00/0000282789.tif     9        NaN\n",
       "319996             imagesa/a/c/z/acz60f00/0011972032.tif    15        NaN\n",
       "319997               imagesu/u/j/m/ujm20a00/10155388.tif     6        NaN\n",
       "319998             imagesd/d/r/r/drr93f00/0000343578.tif     9        NaN\n",
       "319999        imagesp/p/j/x/pjx11d00/518223252+-3253.tif     3        NaN\n",
       "\n",
       "[320000 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create flow from dataframe\n",
    "\n",
    "traindf = pd.read_csv(\"/data/dssg/occrp/data/input/rvl-cdip/labels/train_TH.txt\", dtype=str, sep=\" \")\n",
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagesq/q/o/c/qoc54c00/80035521.tif</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagese/e/w/c/ewc23d00/513280028.tif</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imagesw/w/b/t/wbt26e00/2053453161.tif</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imagesm/m/k/m/mkm05e00/2040792992_2040792994.tif</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imageso/o/e/x/oex80d00/522787731+-7732.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319995</th>\n",
       "      <td>imagesu/u/p/p/upp04f00/0000282789.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319996</th>\n",
       "      <td>imagesa/a/c/z/acz60f00/0011972032.tif</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319997</th>\n",
       "      <td>imagesu/u/j/m/ujm20a00/10155388.tif</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319998</th>\n",
       "      <td>imagesd/d/r/r/drr93f00/0000343578.tif</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319999</th>\n",
       "      <td>imagesp/p/j/x/pjx11d00/518223252+-3253.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename class Unnamed: 2\n",
       "0                    imagesq/q/o/c/qoc54c00/80035521.tif    15        NaN\n",
       "1                   imagese/e/w/c/ewc23d00/513280028.tif     1        NaN\n",
       "2                  imagesw/w/b/t/wbt26e00/2053453161.tif     7        NaN\n",
       "3       imagesm/m/k/m/mkm05e00/2040792992_2040792994.tif    10        NaN\n",
       "4             imageso/o/e/x/oex80d00/522787731+-7732.tif     3        NaN\n",
       "...                                                  ...   ...        ...\n",
       "319995             imagesu/u/p/p/upp04f00/0000282789.tif     9        NaN\n",
       "319996             imagesa/a/c/z/acz60f00/0011972032.tif    15        NaN\n",
       "319997               imagesu/u/j/m/ujm20a00/10155388.tif     6        NaN\n",
       "319998             imagesd/d/r/r/drr93f00/0000343578.tif     9        NaN\n",
       "319999        imagesp/p/j/x/pjx11d00/518223252+-3253.tif     3        NaN\n",
       "\n",
       "[320000 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.drop([\"Unnamed: 2\"], axis=1)\n",
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf[\"filename\"] = \"/data/dssg/occrp/data/input/rvl-cdip/images/\" + traindf[\"filename\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "1         /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "2         /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "3         /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "4         /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "                                ...                        \n",
       "319995    /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "319996    /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "319997    /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "319998    /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "319999    /data/dssg/occrp/data/input/rvl-cdip/images/im...\n",
       "Name: filename, Length: 320000, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320000 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen_d = train_datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    subset=\"training\",\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"class\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    target_size=(227, 227),\n",
    "    batch_size=32,\n",
    "    class_mode=\"sparse\",\n",
    "    color_mode=\"rgb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform labels to vectors\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datagen object\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib64/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib64/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib64/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib64/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib64/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib64/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_47413/340413222.py\", line 2, in <cell line: 2>\n      model.fit(datagen.flow(x_train, y_train, batch_size=32,\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [0,10] and labels shape [320]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_10535]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/thenn/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/thenn/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# fits the model on batches with real-time data augmentation:\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/thenn/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(datagen\u001b[39m.\u001b[39;49mflow(x_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/thenn/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#ch0000009vscode-remote?line=2'>3</a>\u001b[0m          subset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/thenn/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#ch0000009vscode-remote?line=3'>4</a>\u001b[0m          validation_data\u001b[39m=\u001b[39;49mdatagen\u001b[39m.\u001b[39;49mflow(x_train, y_train,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/thenn/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#ch0000009vscode-remote?line=4'>5</a>\u001b[0m          batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, subset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.30.40.120/home/thenn/dssgxdfki2022-occrp/notebooks/preprocessing/image_generator.ipynb#ch0000009vscode-remote?line=5'>6</a>\u001b[0m          steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(x_train) \u001b[39m/\u001b[39;49m \u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib64/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib64/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib64/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib64/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib64/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib64/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib64/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_47413/340413222.py\", line 2, in <cell line: 2>\n      model.fit(datagen.flow(x_train, y_train, batch_size=32,\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/losses.py\", line 1860, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/home/thenn/.local/share/virtualenvs/dssgxdfki2022-occrp-CY4k_1kg/lib/python3.8/site-packages/keras/backend.py\", line 5238, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [0,10] and labels shape [320]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_10535]"
     ]
    }
   ],
   "source": [
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=32, subset=\"training\"),\n",
    "    validation_data=datagen.flow(x_train, y_train, batch_size=8, subset=\"validation\"),\n",
    "    steps_per_epoch=len(x_train) / 32,\n",
    "    epochs=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dssgxdfki2022-occrp-PA4e7Co-')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d7c2732b19896522caf19afdcdc25d9a5a04a879db6235ad72dcf6b8053357f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
